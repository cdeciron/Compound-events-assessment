{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902a3cb-9050-4dad-8446-596db366a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import os\n",
    "import re\n",
    "#Spatial data handling\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import regionmask\n",
    "import rasterio \n",
    "import rasterio.features\n",
    "import pyproj \n",
    "from pyproj import CRS, Transformer\n",
    "from pyproj import Proj, Transformer\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bb9f9-a6e5-4698-8bf7-4191c14ef092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time periods as written in file names from the CDS EURO-CORDEX data \n",
    "## i allows iteration\n",
    "n = 5 #usually 1 or 5, \n",
    "x = 4 #usually 0 or 4, number of years contained in one file \n",
    "### Historical periods\n",
    "hist_period_dates = {\n",
    "    f\"{1971 + i*n}_hist\": f\"{1971 + i*n}0101-{1971 + i*n + x}1231\"\n",
    "    for i in range(5) #6 or 30 years\n",
    "}\n",
    "\n",
    "### Mid-century periods\n",
    "mid_period_dates = {\n",
    "    f\"{i+x}_mid\": f\"{2036 + i*n}0101-{2036 + i*n + x}1231\"\n",
    "    for i in range(5)\n",
    "}\n",
    "\n",
    "### End-century periods\n",
    "end_period_dates = {\n",
    "    f\"{i+x}_end\": f\"{2071 + i*n}0101-{2071 + i*n + x}1231\"\n",
    "    for i in range(5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e132aa6-7cfc-45ed-acc5-709191d6bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to file buildup with help of variables \n",
    "location = 'Volumes'\n",
    "disk = 'LaCie 1'\n",
    "folder = 'Compound_events_study_folder'\n",
    "subfolder = 'Climate_raw_data'\n",
    "gcm_rcm_folder = 'CNRM_CERFACS_CNRM_CM5_CNRM_ALADIN63' #or 'MIROC_MIROC5_CLM_CLMcom4_8_17'.. ect\n",
    "variable_folder = 'Wind'\n",
    "\n",
    "#RIP nomenclature of the GCM-RCM combination\n",
    "rNi1p1 = 'r1i1p1' #'r1i1p1' or 'r2ip1' or 'r3ip1' or 'r2ip1'\n",
    "\n",
    "#Version number\n",
    "v_number = 'v2' #'v1' or 'v2'; in file name\n",
    "\n",
    "#Temporal resolution of the data \n",
    "time_resol = 'day' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efe05b-accb-4b3f-b315-becf2af68b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dictionnaries for folders and file names \n",
    "## Climate variables\n",
    "variables = {\n",
    "    \"wind\": {\n",
    "        \"code\": \"sfcWind\",       \n",
    "        \"folder\": \"Wind\"     \n",
    "    }\n",
    "}\n",
    "\n",
    "##Climate model combinations\n",
    "###Global climate models\n",
    "GCM = {\n",
    "    'CNRM': 'CNRM-CERFACS-CNRM-CM5',\n",
    "    #'MPI': 'MPI-M-MPI-ESM-LR', \n",
    "    #'MIROC': 'MIROC-MIROC5',\n",
    "    #'EcEarth': 'ICHEC-EC-EARTH',\n",
    "    #'NorESM': 'NorESM1-M'\n",
    "    #'HadGEM': 'HadGEM-2'\n",
    "    #'MPI': 'MPI-M-MPI-ESM-LR'\n",
    "}\n",
    "###Regional climate models\n",
    "RCM = {\n",
    "    'R_CNRM':  'CNRM-ALADIN63',\n",
    "    #'ITCP': 'ICTP-RegCM4-6',\n",
    "    #'CLM': 'CLM-CCLM-CLMcom4-8-17'\n",
    "    #'HIRHAM': 'DMI-HIRHAM5'\n",
    "    #'RCA': 'SMHI-RCA4'\n",
    "    #'REMO2015': 'GERICS-REMO2015'\n",
    "}\n",
    "###Dates of the time preiods\n",
    "period_dates = {\n",
    "    'hist': hist_period_dates, \n",
    "    'mid': mid_period_dates, \n",
    "    'end': end_period_dates\n",
    "    \n",
    "}\n",
    "###Scenarios\n",
    "scenario = {\n",
    "    'hist': 'historical', \n",
    "    'RCP': 'rcp85'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da31dcf-1cf2-4e0e-a9e1-685239d4a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather the files by period based on the dates in the file name\n",
    "def generate_file_paths(var_key):\n",
    "    #Create one list for each period \n",
    "    files = {'hist': [], 'mid': [], 'end': []}\n",
    "    \n",
    "    if var_key not in variables:\n",
    "        raise ValueError(f\"Variable '{var_key}' not found in variables dictionary.\")\n",
    "\n",
    "    #Name of folder and var_code based on definition \n",
    "    var_info = variables[var_key]\n",
    "    var_code = var_info['code']\n",
    "    folder_name = var_info['folder']\n",
    "\n",
    "    #For each GCM_RCM combination and each period (hist, mid, end)\n",
    "    for gcm_key, gcm_val in GCM.items():\n",
    "        for rcm_key, rcm_val in RCM.items():\n",
    "            for period_type, period_dict in period_dates.items():\n",
    "                scen = scenario['hist'] if period_type == 'hist' else scenario['RCP']\n",
    "                for date_range in period_dict.values():\n",
    "                    file_path = (\n",
    "                        f\"/{location}/{disk}/{folder}/{subfolder}/{gcm_rcm_folder}/Climate_raw_data/{variable_folder}/\"\n",
    "                       f\"{var_code}_EUR-11_{gcm_val}_{scen}_{rNi1p1}_{rcm_val}_{v_number}_{time_resol}_{date_range}.nc\"\n",
    "                    )\n",
    "                    #File path is registered in lists for periods \n",
    "                    if os.path.exists(file_path):\n",
    "                        files[period_type].append(file_path)\n",
    "                    else:\n",
    "                        print(f\"Missing: {file_path}\")\n",
    "\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca03c7d-b019-4261-88a1-a14fc37deb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each period one dataset is created \n",
    "def create_wind_datasets_from_file_dict(file_dict):\n",
    "    return {\n",
    "        \"hist\": xr.open_mfdataset(file_dict[\"hist\"], combine=\"by_coords\", decode_coords=\"all\"),\n",
    "        \"mid\":  xr.open_mfdataset(file_dict[\"mid\"],  combine=\"by_coords\", decode_coords=\"all\"),\n",
    "        \"end\":  xr.open_mfdataset(file_dict[\"end\"],  combine=\"by_coords\", decode_coords=\"all\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a0db2-0a88-435f-b25a-428535dd7b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dict = generate_file_paths(\"wind\")  \n",
    "wind_datasets = create_wind_datasets_from_file_dict(file_dict)\n",
    "\n",
    "wind_ds_hist = wind_datasets[\"hist\"]\n",
    "wind_ds_mid  = wind_datasets[\"mid\"]\n",
    "wind_ds_end  = wind_datasets[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c65d51-2b1c-4708-9d48-f5bf17a46393",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_datasets = {\n",
    "    'hist': xr.open_mfdataset(file_dict['hist'], chunks={'time': 100}),\n",
    "    'mid':  xr.open_mfdataset(file_dict['mid'], chunks={'time': 100}),\n",
    "    'end':  xr.open_mfdataset(file_dict['end'], chunks={'time': 100}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c1b03-83a9-4780-8791-6d4752e572cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to folder of shapefiles\n",
    "shp_path = '/Users/Camille//Documents/Stages/Stage S.Mayer/Cartes/Shapefiles'\n",
    "#Enter the folder path to the shapefiles of Norway and for regions\n",
    "norway_shp_folder = f'{shp_path}/Norway_E_maps.qgz'\n",
    "elspot_regions_folder = f'{shp_path}/Elspot_regions_PostProcessed'\n",
    "\n",
    "#Define your geographical coordinates system\n",
    "crs_name = \"EPSG:4326\" #WGS84\n",
    "\n",
    "#bboxes available on bbox finder to determine the square area of your regions\n",
    "bbox_no  = [4.096012, 57.736234, 32.177067, 71.599506] # For all Norway (bounding box)\n",
    "bbox_er1 = [6.833496, 58.688359, 13.908691, 62.885205] #bbox for NO1 region\n",
    "bbox_er2 = [4.514952, 57.705340, 12.952452, 60.963527] #bbox for NO2 region\n",
    "bbox_er3 = [1.593189, 58.712348, 17.149830, 65.848681] #bbox for NO3 region\n",
    "bbox_er4 = [7.646484, 63.918058, 32.167969, 71.635993] #bbox for NO4 region\n",
    "bbox_er5 = [-1.113567, 56.213244, 14.443073, 63.874893] #bbox for NO5 region\n",
    "\n",
    "#Transformation of the data's crs (rotated pole) to a WGS84 (EPSG:4326)\n",
    "original_crs = ccrs.RotatedPole(pole_latitude=39.25, pole_longitude=-162)\n",
    "transformer = pyproj.Transformer.from_crs(crs_name, original_crs)\n",
    "\n",
    "#New bbox coordinates matching EURO-CORDEX projection\n",
    "RLON_MIN, RLAT_MIN = transformer.transform(bbox_no[1], bbox_no[0])\n",
    "RLON_MAX, RLAT_MAX = transformer.transform(bbox_no[3], bbox_no[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefcc95-4522-48d4-a2cc-d596e213844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the file path to your shapefiles\n",
    "shapefiles = {\n",
    "    'Norway': f'{shp_path}/Norway_E_maps.qgz/gadm41_NOR_1.shp', \n",
    "    'NO1': f'{shp_path}/Elspot_regions_PostProcessed/NO1_Land_Availability.shp', \n",
    "    'NO2': f'{shp_path}/Elspot_regions_PostProcessed/NO2_Land_Availability.shp', \n",
    "    'NO3': f'{shp_path}/Elspot_regions_PostProcessed/NO3_Land_Availability.shp', \n",
    "    'NO4': f'{shp_path}/Elspot_regions_PostProcessed/NO4_Land_Availability.shp', \n",
    "    'NO5': f'{shp_path}/Elspot_regions_PostProcessed/NO5_Land_Availability.shp'\n",
    "}\n",
    "\n",
    "bounding_boxes = {\n",
    "    'NO': bbox_no, \n",
    "    'NO1': bbox_er1, \n",
    "    'NO2': bbox_er2, \n",
    "    'NO3': bbox_er3,\n",
    "    'NO4': bbox_er4, \n",
    "    'NO5': bbox_er5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803cf79-2d0a-4e84-b0a4-3bb86f64cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read the shapefiles paths and convert it to WGS84\n",
    "shapes = {}\n",
    "for name, path in shapefiles.items():\n",
    "    gdf = gpd.read_file(path)\n",
    "    gdf = gdf.to_crs(crs_name)\n",
    "    shapes[name] = gdf\n",
    "\n",
    "#Set crs to WGS84 for the datasets \n",
    "for name, ds in wind_datasets.items():\n",
    "    wind_datasets[name] = ds.rio.write_crs(crs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309450e-f19f-48ee-b915-7ff728ad2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrain the data to Norway bbox only instead of whole Europe in original downloaded data \n",
    "def clip_dataset_with_bbox(ds, region_name, bounding_boxes):\n",
    "    bbox = bounding_boxes[region_name]\n",
    "    coords = ds.coords.keys()\n",
    "\n",
    "    #If coordinates are called 'rlat' and 'rlon' format\n",
    "    if 'rlat' in coords and 'rlon' in coords:\n",
    "        # rotated pole coordinates - use .sel()\n",
    "        RLON_MIN, RLAT_MIN = transformer.transform(bbox[1], bbox[0])  # lat, lon order!\n",
    "        RLON_MAX, RLAT_MAX = transformer.transform(bbox[3], bbox[2])\n",
    "        ds_sliced = ds.sel(rlat=slice(RLAT_MIN, RLAT_MAX), rlon=slice(RLON_MIN, RLON_MAX))\n",
    "        return ds_sliced\n",
    "\n",
    "    #If coordinates are called 'x' and 'y' format\n",
    "    elif 'x' in coords and 'y' in coords:\n",
    "        # lat/lon are variables, not coordinates -> mask using .where()\n",
    "        lon = ds['lon']\n",
    "        lat = ds['lat']\n",
    "\n",
    "        mask = (\n",
    "            (lon >= bbox[0]) & (lon <= bbox[2]) &\n",
    "            (lat >= bbox[1]) & (lat <= bbox[3])\n",
    "        )\n",
    "\n",
    "        if hasattr(mask, 'compute'):\n",
    "            mask = mask.compute()\n",
    "\n",
    "        if mask.sum().values == 0:\n",
    "            print(f\"✗ No data points selected for region {region_name}\")\n",
    "            return None\n",
    "\n",
    "        ds_sliced = ds.where(mask, drop=True)\n",
    "        return ds_sliced\n",
    "\n",
    "    else:\n",
    "        print(f\"✗ Dataset does not have known spatial coords for region {region_name}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb88e6-3a30-4082-ae28-0fc01371e3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sliced_by_region = {}\n",
    "#Data is sliced for each region based on the bounding boxes coordinates\n",
    "for period, ds in wind_datasets.items():\n",
    "    print(f\"\\n=== Period: {period} ===\")\n",
    "    sliced_by_region[period] = {}\n",
    "    for region in bounding_boxes:\n",
    "        sliced = clip_dataset_with_bbox(ds, region, bounding_boxes)\n",
    "        if sliced is None:\n",
    "            print(f\"✗ Failed to slice {period} for {region}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9922db4-3e93-49cd-a2f0-074a6e8c1257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute regional mean time series for overlapping regions using a 3D mask.\n",
    "#Returns a DataFrame with time as index and regions as columns\n",
    "def compute_regional_means(ds, shapes):\n",
    "    # Create regionmask.Regions object\n",
    "    regions = regionmask.Regions([gdf.geometry.values[0] for gdf in shapes.values()],\n",
    "                                 names=list(shapes.keys()))\n",
    "\n",
    "    # Create a 3D mask (region × y × x)\n",
    "    mask_3d = regions.mask_3D(ds)\n",
    "\n",
    "    df = pd.DataFrame(index=pd.to_datetime(ds.time.values))\n",
    "\n",
    "    # Iterate over regions shapefiles and compute mean\n",
    "    for i, name in enumerate(shapes.keys()):\n",
    "        region_mask = mask_3d.isel(region=i)\n",
    "        masked_data = ds.rsds.where(region_mask)\n",
    "        regional_mean = masked_data.mean(dim=(\"y\", \"x\"), skipna=True)\n",
    "        df[name] = regional_mean.compute().values\n",
    "\n",
    "    return df\n",
    "\n",
    "# ===== Run and save CSVs =====\n",
    "#Enter your output file\n",
    "output_dir = f\"/{location}/{disk}/{folder}/{subfolder}/{gcm_rcm_folder}/Post_processed_data/sfc_wind/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#Create a csv for each period of time containing data for the 5 regions+Norway \n",
    "for period, ds in wind_datasets.items():\n",
    "    print(f\"Processing {period}...\")\n",
    "    df = compute_regional_means(ds, shapes)\n",
    "    output_path = os.path.join(output_dir, f\"regional_mean_wind_{period}.csv\")\n",
    "    df.to_csv(output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd8e14-b43c-460e-a3fe-4429391a00a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
